{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71a5e425-99e2-4587-abb0-200b9ff73a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "172e39eb-fb52-491f-8145-5156ce71f307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>none</th>\n",
       "      <th>count</th>\n",
       "      <th>known</th>\n",
       "      <th>to_predict</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0.37</td>\n",
       "      <td>-0.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-0.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-08</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-09</th>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>-0.140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-24</th>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>-0.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-25</th>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-29</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-30</th>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-31</th>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.379999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            positive  negative  neutral  none  count  known  to_predict\n",
       "Date                                                                   \n",
       "2018-01-03        22        11        1     0     34   0.37   -0.190000\n",
       "2018-01-04        24         8        4     0     36  -0.19   -0.040000\n",
       "2018-01-05        21         5        2     0     28  -0.04    0.010000\n",
       "2018-01-08        24         1        1     0     26   0.01   -0.140000\n",
       "2018-01-09        25         8        5     0     38  -0.14   -0.140000\n",
       "...              ...       ...      ...   ...    ...    ...         ...\n",
       "2018-05-24        14         5        3     0     22  -0.17   -0.040000\n",
       "2018-05-25        14         3        1     0     18  -0.04    0.120000\n",
       "2018-05-29        20         5        2     0     27   0.12    0.010000\n",
       "2018-05-30        24         4        1     0     29   0.01   -0.120000\n",
       "2018-05-31        14         2        0     0     16  -0.12    0.379999\n",
       "\n",
       "[103 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/processed_sa_bert_price_diff.csv', index_col=[0])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29e1ae32-a73c-4953-a001-7e0feebdfece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>none</th>\n",
       "      <th>count</th>\n",
       "      <th>known</th>\n",
       "      <th>to_predict</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0.37</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-08</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-09</th>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-24</th>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-25</th>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-29</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-30</th>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-31</th>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            positive  negative  neutral  none  count  known  to_predict\n",
       "Date                                                                   \n",
       "2018-01-03        22        11        1     0     34   0.37          -1\n",
       "2018-01-04        24         8        4     0     36  -0.19          -1\n",
       "2018-01-05        21         5        2     0     28  -0.04           1\n",
       "2018-01-08        24         1        1     0     26   0.01          -1\n",
       "2018-01-09        25         8        5     0     38  -0.14          -1\n",
       "...              ...       ...      ...   ...    ...    ...         ...\n",
       "2018-05-24        14         5        3     0     22  -0.17          -1\n",
       "2018-05-25        14         3        1     0     18  -0.04           1\n",
       "2018-05-29        20         5        2     0     27   0.12           1\n",
       "2018-05-30        24         4        1     0     29   0.01          -1\n",
       "2018-05-31        14         2        0     0     16  -0.12           1\n",
       "\n",
       "[103 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sa_movement_df():\n",
    "    def _map(val):\n",
    "        if val <= 0:\n",
    "            return -1\n",
    "        else:\n",
    "            return 1\n",
    "    df = pd.read_csv('./data/processed_sa_bert_price_diff.csv', index_col=[0])\n",
    "    df['to_predict'] = df['to_predict'].apply(lambda x:_map(x))\n",
    "    return df\n",
    "# plt.plot(sa_movement_df()['to_predict'])\n",
    "sa_movement_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "add184b7-9377-4229-bfc7-1ef711ab45f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>quality_positive</th>\n",
       "      <th>quality_negative</th>\n",
       "      <th>quality_neutral</th>\n",
       "      <th>quality_none</th>\n",
       "      <th>connectivity_positive</th>\n",
       "      <th>connectivity_negative</th>\n",
       "      <th>connectivity_neutral</th>\n",
       "      <th>connectivity_none</th>\n",
       "      <th>usability_positive</th>\n",
       "      <th>...</th>\n",
       "      <th>design features_positive</th>\n",
       "      <th>design features_negative</th>\n",
       "      <th>design features_neutral</th>\n",
       "      <th>design features_none</th>\n",
       "      <th>price_positive</th>\n",
       "      <th>price_negative</th>\n",
       "      <th>price_neutral</th>\n",
       "      <th>price_none</th>\n",
       "      <th>known</th>\n",
       "      <th>to_predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.37</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-09</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>...</td>\n",
       "      <td>0.184211</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2018-05-24</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2018-05-25</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2018-05-29</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>2018-05-30</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2018-05-31</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  quality_positive  quality_negative  quality_neutral   \n",
       "0    2018-01-03          0.147059          0.117647              0.0  \\\n",
       "1    2018-01-04          0.250000          0.111111              0.0   \n",
       "2    2018-01-05          0.285714          0.035714              0.0   \n",
       "3    2018-01-08          0.307692          0.000000              0.0   \n",
       "4    2018-01-09          0.210526          0.078947              0.0   \n",
       "..          ...               ...               ...              ...   \n",
       "98   2018-05-24          0.318182          0.136364              0.0   \n",
       "99   2018-05-25          0.277778          0.000000              0.0   \n",
       "100  2018-05-29          0.222222          0.037037              0.0   \n",
       "101  2018-05-30          0.379310          0.068966              0.0   \n",
       "102  2018-05-31          0.562500          0.062500              0.0   \n",
       "\n",
       "     quality_none  connectivity_positive  connectivity_negative   \n",
       "0        0.735294                    0.0                    0.0  \\\n",
       "1        0.638889                    0.0                    0.0   \n",
       "2        0.678571                    0.0                    0.0   \n",
       "3        0.692308                    0.0                    0.0   \n",
       "4        0.710526                    0.0                    0.0   \n",
       "..            ...                    ...                    ...   \n",
       "98       0.545455                    0.0                    0.0   \n",
       "99       0.722222                    0.0                    0.0   \n",
       "100      0.740741                    0.0                    0.0   \n",
       "101      0.551724                    0.0                    0.0   \n",
       "102      0.375000                    0.0                    0.0   \n",
       "\n",
       "     connectivity_neutral  connectivity_none  usability_positive  ...   \n",
       "0                     0.0                1.0            0.058824  ...  \\\n",
       "1                     0.0                1.0            0.055556  ...   \n",
       "2                     0.0                1.0            0.035714  ...   \n",
       "3                     0.0                1.0            0.038462  ...   \n",
       "4                     0.0                1.0            0.052632  ...   \n",
       "..                    ...                ...                 ...  ...   \n",
       "98                    0.0                1.0            0.045455  ...   \n",
       "99                    0.0                1.0            0.055556  ...   \n",
       "100                   0.0                1.0            0.037037  ...   \n",
       "101                   0.0                1.0            0.034483  ...   \n",
       "102                   0.0                1.0            0.125000  ...   \n",
       "\n",
       "     design features_positive  design features_negative   \n",
       "0                    0.264706                  0.029412  \\\n",
       "1                    0.166667                  0.083333   \n",
       "2                    0.178571                  0.000000   \n",
       "3                    0.269231                  0.000000   \n",
       "4                    0.184211                  0.078947   \n",
       "..                        ...                       ...   \n",
       "98                   0.136364                  0.000000   \n",
       "99                   0.055556                  0.000000   \n",
       "100                  0.148148                  0.037037   \n",
       "101                  0.137931                  0.137931   \n",
       "102                  0.187500                  0.000000   \n",
       "\n",
       "     design features_neutral  design features_none  price_positive   \n",
       "0                        0.0              0.705882        0.088235  \\\n",
       "1                        0.0              0.750000        0.055556   \n",
       "2                        0.0              0.821429        0.107143   \n",
       "3                        0.0              0.730769        0.115385   \n",
       "4                        0.0              0.736842        0.105263   \n",
       "..                       ...                   ...             ...   \n",
       "98                       0.0              0.863636        0.227273   \n",
       "99                       0.0              0.944444        0.277778   \n",
       "100                      0.0              0.814815        0.074074   \n",
       "101                      0.0              0.724138        0.068966   \n",
       "102                      0.0              0.812500        0.125000   \n",
       "\n",
       "     price_negative  price_neutral  price_none  known  to_predict  \n",
       "0          0.000000            0.0    0.911765   0.37          -1  \n",
       "1          0.000000            0.0    0.944444  -0.19          -1  \n",
       "2          0.000000            0.0    0.892857  -0.04           1  \n",
       "3          0.000000            0.0    0.884615   0.01          -1  \n",
       "4          0.000000            0.0    0.894737  -0.14          -1  \n",
       "..              ...            ...         ...    ...         ...  \n",
       "98         0.000000            0.0    0.772727  -0.17          -1  \n",
       "99         0.000000            0.0    0.722222  -0.04           1  \n",
       "100        0.037037            0.0    0.888889   0.12           1  \n",
       "101        0.034483            0.0    0.896552   0.01          -1  \n",
       "102        0.000000            0.0    0.875000  -0.12           1  \n",
       "\n",
       "[103 rows x 39 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def absa_movement_df():\n",
    "    def _map(val):\n",
    "        if val <= 0: # 0 就是亏了，还有手续费等等，简化模型为binary classification\n",
    "            return -1\n",
    "        else:\n",
    "            return 1\n",
    "    absa_df = pd.read_csv('./data/processed_absa_price_diff.csv')\n",
    "\n",
    "#     absa_df = absa_df.drop(columns=['Date'])\n",
    "#     print(absa_df.columns[:-3])\n",
    "    for col in absa_df.columns[:-3]:\n",
    "        if col == 'Date':\n",
    "            continue\n",
    "        absa_df[col] /= absa_df['count']\n",
    "    absa_df = absa_df.drop(columns=['count'])\n",
    "    absa_df['to_predict'] = absa_df['to_predict'].apply(lambda x:_map(x))\n",
    "    return absa_df\n",
    "absa_movement_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a728d201-6984-4634-8ba1-4b3128a3573c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quality_positive</th>\n",
       "      <th>quality_negative</th>\n",
       "      <th>quality_neutral</th>\n",
       "      <th>quality_none</th>\n",
       "      <th>connectivity_positive</th>\n",
       "      <th>connectivity_negative</th>\n",
       "      <th>connectivity_neutral</th>\n",
       "      <th>connectivity_none</th>\n",
       "      <th>usability_positive</th>\n",
       "      <th>usability_negative</th>\n",
       "      <th>...</th>\n",
       "      <th>operation performance_none</th>\n",
       "      <th>design features_positive</th>\n",
       "      <th>design features_negative</th>\n",
       "      <th>design features_neutral</th>\n",
       "      <th>design features_none</th>\n",
       "      <th>price_positive</th>\n",
       "      <th>price_negative</th>\n",
       "      <th>price_neutral</th>\n",
       "      <th>price_none</th>\n",
       "      <th>to_predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.184211</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     quality_positive  quality_negative  quality_neutral  quality_none   \n",
       "0            0.147059          0.117647              0.0      0.735294  \\\n",
       "1            0.250000          0.111111              0.0      0.638889   \n",
       "2            0.285714          0.035714              0.0      0.678571   \n",
       "3            0.307692          0.000000              0.0      0.692308   \n",
       "4            0.210526          0.078947              0.0      0.710526   \n",
       "..                ...               ...              ...           ...   \n",
       "98           0.318182          0.136364              0.0      0.545455   \n",
       "99           0.277778          0.000000              0.0      0.722222   \n",
       "100          0.222222          0.037037              0.0      0.740741   \n",
       "101          0.379310          0.068966              0.0      0.551724   \n",
       "102          0.562500          0.062500              0.0      0.375000   \n",
       "\n",
       "     connectivity_positive  connectivity_negative  connectivity_neutral   \n",
       "0                      0.0                    0.0                   0.0  \\\n",
       "1                      0.0                    0.0                   0.0   \n",
       "2                      0.0                    0.0                   0.0   \n",
       "3                      0.0                    0.0                   0.0   \n",
       "4                      0.0                    0.0                   0.0   \n",
       "..                     ...                    ...                   ...   \n",
       "98                     0.0                    0.0                   0.0   \n",
       "99                     0.0                    0.0                   0.0   \n",
       "100                    0.0                    0.0                   0.0   \n",
       "101                    0.0                    0.0                   0.0   \n",
       "102                    0.0                    0.0                   0.0   \n",
       "\n",
       "     connectivity_none  usability_positive  usability_negative  ...   \n",
       "0                  1.0            0.058824                 0.0  ...  \\\n",
       "1                  1.0            0.055556                 0.0  ...   \n",
       "2                  1.0            0.035714                 0.0  ...   \n",
       "3                  1.0            0.038462                 0.0  ...   \n",
       "4                  1.0            0.052632                 0.0  ...   \n",
       "..                 ...                 ...                 ...  ...   \n",
       "98                 1.0            0.045455                 0.0  ...   \n",
       "99                 1.0            0.055556                 0.0  ...   \n",
       "100                1.0            0.037037                 0.0  ...   \n",
       "101                1.0            0.034483                 0.0  ...   \n",
       "102                1.0            0.125000                 0.0  ...   \n",
       "\n",
       "     operation performance_none  design features_positive   \n",
       "0                      0.735294                  0.264706  \\\n",
       "1                      0.750000                  0.166667   \n",
       "2                      0.785714                  0.178571   \n",
       "3                      0.692308                  0.269231   \n",
       "4                      0.815789                  0.184211   \n",
       "..                          ...                       ...   \n",
       "98                     0.636364                  0.136364   \n",
       "99                     0.777778                  0.055556   \n",
       "100                    0.740741                  0.148148   \n",
       "101                    0.689655                  0.137931   \n",
       "102                    0.812500                  0.187500   \n",
       "\n",
       "     design features_negative  design features_neutral  design features_none   \n",
       "0                    0.029412                      0.0              0.705882  \\\n",
       "1                    0.083333                      0.0              0.750000   \n",
       "2                    0.000000                      0.0              0.821429   \n",
       "3                    0.000000                      0.0              0.730769   \n",
       "4                    0.078947                      0.0              0.736842   \n",
       "..                        ...                      ...                   ...   \n",
       "98                   0.000000                      0.0              0.863636   \n",
       "99                   0.000000                      0.0              0.944444   \n",
       "100                  0.037037                      0.0              0.814815   \n",
       "101                  0.137931                      0.0              0.724138   \n",
       "102                  0.000000                      0.0              0.812500   \n",
       "\n",
       "     price_positive  price_negative  price_neutral  price_none  to_predict  \n",
       "0          0.088235        0.000000            0.0    0.911765          -1  \n",
       "1          0.055556        0.000000            0.0    0.944444          -1  \n",
       "2          0.107143        0.000000            0.0    0.892857           1  \n",
       "3          0.115385        0.000000            0.0    0.884615          -1  \n",
       "4          0.105263        0.000000            0.0    0.894737          -1  \n",
       "..              ...             ...            ...         ...         ...  \n",
       "98         0.227273        0.000000            0.0    0.772727          -1  \n",
       "99         0.277778        0.000000            0.0    0.722222           1  \n",
       "100        0.074074        0.037037            0.0    0.888889           1  \n",
       "101        0.068966        0.034483            0.0    0.896552          -1  \n",
       "102        0.125000        0.000000            0.0    0.875000           1  \n",
       "\n",
       "[103 rows x 37 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def absa_movement_no_known_df():\n",
    "    def _map(val):\n",
    "        if val <= 0:\n",
    "            return -1\n",
    "        else:\n",
    "            return 1\n",
    "    absa_df = pd.read_csv('./data/processed_absa_price_diff.csv')\n",
    "\n",
    "#     absa_df = absa_df.drop(columns=['Date'])\n",
    "#     print(absa_df.columns[:-3])\n",
    "    for col in absa_df.columns[:-3]:\n",
    "        if col == 'Date':\n",
    "            continue\n",
    "        absa_df[col] /= absa_df['count']\n",
    "    absa_df = absa_df.drop(columns=['count','known'])\n",
    "    absa_df['to_predict'] = absa_df['to_predict'].apply(lambda x:_map(x))\n",
    "    absa_df = absa_df.drop(columns=['Date'])\n",
    "    \n",
    "    return absa_df\n",
    "absa_movement_no_known_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38f7f8c6-4da5-4427-82c4-b30a342a80ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>known</th>\n",
       "      <th>to_predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>0.37</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-09</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2018-05-24</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2018-05-25</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2018-05-29</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>2018-05-30</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2018-05-31</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  known  to_predict\n",
       "0    2018-01-03   0.37          -1\n",
       "1    2018-01-04  -0.19          -1\n",
       "2    2018-01-05  -0.04           1\n",
       "3    2018-01-08   0.01          -1\n",
       "4    2018-01-09  -0.14          -1\n",
       "..          ...    ...         ...\n",
       "98   2018-05-24  -0.17          -1\n",
       "99   2018-05-25  -0.04           1\n",
       "100  2018-05-29   0.12           1\n",
       "101  2018-05-30   0.01          -1\n",
       "102  2018-05-31  -0.12           1\n",
       "\n",
       "[103 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pure_movement_df():\n",
    "    def _map(val):\n",
    "        if val <= 0:\n",
    "            return -1\n",
    "        else:\n",
    "            return 1\n",
    "    df = pd.read_csv('./data/processed_sa_bert_price_diff.csv')\n",
    "    df = df[['Date','known','to_predict']]\n",
    "    df['to_predict'] = df['to_predict'].apply(lambda x:_map(x))\n",
    "    return df\n",
    "pure_movement_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a8a360-1c98-4f6d-8839-78e64861e73a",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73138a42-64c0-4c97-b967-8ecebb2a4353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abs(pearson)</th>\n",
       "      <th>abs(spearman)</th>\n",
       "      <th>non-zero count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>to_predict</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>usability_positive</th>\n",
       "      <td>0.111567</td>\n",
       "      <td>0.146538</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>design features_negative</th>\n",
       "      <td>0.212056</td>\n",
       "      <td>0.146490</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>general_neutral</th>\n",
       "      <td>0.154704</td>\n",
       "      <td>0.120351</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_positive</th>\n",
       "      <td>0.086488</td>\n",
       "      <td>0.103642</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality_positive</th>\n",
       "      <td>0.156333</td>\n",
       "      <td>0.094395</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>operation performance_negative</th>\n",
       "      <td>0.080409</td>\n",
       "      <td>0.090183</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>operation performance_positive</th>\n",
       "      <td>0.094496</td>\n",
       "      <td>0.060943</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>general_negative</th>\n",
       "      <td>0.063954</td>\n",
       "      <td>0.049698</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>design features_positive</th>\n",
       "      <td>0.048753</td>\n",
       "      <td>0.047697</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>general_positive</th>\n",
       "      <td>0.014869</td>\n",
       "      <td>0.015566</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality_negative</th>\n",
       "      <td>0.009054</td>\n",
       "      <td>0.007771</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                abs(pearson)  abs(spearman)  non-zero count\n",
       "to_predict                          1.000000       1.000000             103\n",
       "usability_positive                  0.111567       0.146538              73\n",
       "design features_negative            0.212056       0.146490              45\n",
       "general_neutral                     0.154704       0.120351              23\n",
       "price_positive                      0.086488       0.103642              84\n",
       "quality_positive                    0.156333       0.094395             100\n",
       "operation performance_negative      0.080409       0.090183              81\n",
       "operation performance_positive      0.094496       0.060943              99\n",
       "general_negative                    0.063954       0.049698              93\n",
       "design features_positive            0.048753       0.047697              97\n",
       "general_positive                    0.014869       0.015566             102\n",
       "quality_negative                    0.009054       0.007771              68"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "df = absa_movement_no_known_df()\n",
    "\n",
    "# Calculate correlation with 'to_predict' using Pearson and Spearman methods\n",
    "corr_pearson = df.corr(method='pearson')['to_predict'].abs()\n",
    "corr_spearman = df.corr(method='spearman')['to_predict'].abs()\n",
    "corr_df = pd.concat([corr_pearson, corr_spearman], axis=1, keys=['pearson', 'spearman'])\n",
    "corr_df = corr_df.sort_values(by='spearman', ascending=False)\n",
    "\n",
    "# Calculate non-zero count for each column\n",
    "non_zero_count = []\n",
    "for col in corr_df.index:\n",
    "    non_zero_count.append(df[col].astype(bool).sum(axis=0))\n",
    "\n",
    "# Combine into a dataframe\n",
    "data = {'abs(pearson)': corr_df['pearson'].values,\n",
    "        'abs(spearman)': corr_df['spearman'].values,\n",
    "        'non-zero count': non_zero_count}\n",
    "result_df = pd.DataFrame(data, index=corr_df.index)\n",
    "\n",
    "# Filter by non-zero count and exclude 'none' sentiment\n",
    "result_df = result_df[(result_df['non-zero count'] >= 20) & (~result_df.index.str.contains('none'))]\n",
    "\n",
    "# Sort by spearman correlation\n",
    "result_df = result_df.sort_values(by='abs(spearman)', ascending=False)\n",
    "\n",
    "# Print result\n",
    "result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82e43842-a34e-47f4-a324-32c6ad46063a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abs(pearson)</th>\n",
       "      <th>abs(spearman)</th>\n",
       "      <th>non-zero count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>usability_positive</th>\n",
       "      <td>0.111567</td>\n",
       "      <td>0.146538</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>design features_negative</th>\n",
       "      <td>0.212056</td>\n",
       "      <td>0.146490</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>general_neutral</th>\n",
       "      <td>0.154704</td>\n",
       "      <td>0.120351</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_positive</th>\n",
       "      <td>0.086488</td>\n",
       "      <td>0.103642</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality_positive</th>\n",
       "      <td>0.156333</td>\n",
       "      <td>0.094395</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>operation performance_negative</th>\n",
       "      <td>0.080409</td>\n",
       "      <td>0.090183</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>operation performance_positive</th>\n",
       "      <td>0.094496</td>\n",
       "      <td>0.060943</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>general_negative</th>\n",
       "      <td>0.063954</td>\n",
       "      <td>0.049698</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>design features_positive</th>\n",
       "      <td>0.048753</td>\n",
       "      <td>0.047697</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>general_positive</th>\n",
       "      <td>0.014869</td>\n",
       "      <td>0.015566</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality_negative</th>\n",
       "      <td>0.009054</td>\n",
       "      <td>0.007771</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                abs(pearson)  abs(spearman)  non-zero count\n",
       "usability_positive                  0.111567       0.146538              73\n",
       "design features_negative            0.212056       0.146490              45\n",
       "general_neutral                     0.154704       0.120351              23\n",
       "price_positive                      0.086488       0.103642              84\n",
       "quality_positive                    0.156333       0.094395             100\n",
       "operation performance_negative      0.080409       0.090183              81\n",
       "operation performance_positive      0.094496       0.060943              99\n",
       "general_negative                    0.063954       0.049698              93\n",
       "design features_positive            0.048753       0.047697              97\n",
       "general_positive                    0.014869       0.015566             102\n",
       "quality_negative                    0.009054       0.007771              68"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = result_df.drop('to_predict')\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b123246f-42e9-41db-92c0-4b08abf012b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['usability_positive', 'design features_negative', 'general_neutral',\n",
       "       'price_positive', 'quality_positive', 'operation performance_negative',\n",
       "       'operation performance_positive', 'general_negative',\n",
       "       'design features_positive', 'general_positive', 'quality_negative'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d271dc-49c2-4649-9d3b-316c66519698",
   "metadata": {},
   "source": [
    "# generalized linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b901092-7830-4f8f-bb6d-2b7967caf0cc",
   "metadata": {},
   "source": [
    "## Logistic Regression with Increasing Number of Features in the order of correlation (no previous price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88997f93-bde7-4bdc-bad1-7af4d215576a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: ['usability_positive']\n",
      "K = 5, Accuracy: 0.5814 +/- 0.0894\n",
      "Confusion Matrix:\n",
      "[[12.   0. ]\n",
      " [ 8.6  0. ]]\n",
      "\n",
      "K = 10, Accuracy: 0.5791 +/- 0.1262\n",
      "Confusion Matrix:\n",
      "[[6.  0. ]\n",
      " [4.3 0. ]]\n",
      "\n",
      "Model: ['usability_positive', 'design features_negative']\n",
      "K = 5, Accuracy: 0.5814 +/- 0.0894\n",
      "Confusion Matrix:\n",
      "[[12.   0. ]\n",
      " [ 8.6  0. ]]\n",
      "\n",
      "K = 10, Accuracy: 0.5791 +/- 0.1262\n",
      "Confusion Matrix:\n",
      "[[6.  0. ]\n",
      " [4.3 0. ]]\n",
      "\n",
      "Model: ['usability_positive', 'design features_negative', 'general_neutral']\n",
      "K = 5, Accuracy: 0.5814 +/- 0.0894\n",
      "Confusion Matrix:\n",
      "[[12.   0. ]\n",
      " [ 8.6  0. ]]\n",
      "\n",
      "K = 10, Accuracy: 0.5791 +/- 0.1262\n",
      "Confusion Matrix:\n",
      "[[6.  0. ]\n",
      " [4.3 0. ]]\n",
      "\n",
      "Model: ['usability_positive', 'design features_negative', 'general_neutral', 'price_positive']\n",
      "K = 5, Accuracy: 0.5814 +/- 0.0894\n",
      "Confusion Matrix:\n",
      "[[12.   0. ]\n",
      " [ 8.6  0. ]]\n",
      "\n",
      "K = 10, Accuracy: 0.5791 +/- 0.1262\n",
      "Confusion Matrix:\n",
      "[[6.  0. ]\n",
      " [4.3 0. ]]\n",
      "\n",
      "Model: ['usability_positive', 'design features_negative', 'general_neutral', 'price_positive', 'quality_positive']\n",
      "K = 5, Accuracy: 0.5910 +/- 0.0953\n",
      "Confusion Matrix:\n",
      "[[12.   0. ]\n",
      " [ 8.4  0.2]]\n",
      "\n",
      "K = 10, Accuracy: 0.5891 +/- 0.1235\n",
      "Confusion Matrix:\n",
      "[[6.  0. ]\n",
      " [4.2 0.1]]\n",
      "\n",
      "Model: ['usability_positive', 'design features_negative', 'general_neutral', 'price_positive', 'quality_positive', 'operation performance_negative']\n",
      "K = 5, Accuracy: 0.5910 +/- 0.0953\n",
      "Confusion Matrix:\n",
      "[[12.   0. ]\n",
      " [ 8.4  0.2]]\n",
      "\n",
      "K = 10, Accuracy: 0.5800 +/- 0.1230\n",
      "Confusion Matrix:\n",
      "[[5.9 0.1]\n",
      " [4.2 0.1]]\n",
      "\n",
      "Model: ['usability_positive', 'design features_negative', 'general_neutral', 'price_positive', 'quality_positive', 'operation performance_negative', 'operation performance_positive']\n",
      "K = 5, Accuracy: 0.5910 +/- 0.0953\n",
      "Confusion Matrix:\n",
      "[[12.   0. ]\n",
      " [ 8.4  0.2]]\n",
      "\n",
      "K = 10, Accuracy: 0.5791 +/- 0.1262\n",
      "Confusion Matrix:\n",
      "[[6.  0. ]\n",
      " [4.3 0. ]]\n",
      "\n",
      "Model: ['usability_positive', 'design features_negative', 'general_neutral', 'price_positive', 'quality_positive', 'operation performance_negative', 'operation performance_positive', 'general_negative']\n",
      "K = 5, Accuracy: 0.5910 +/- 0.0953\n",
      "Confusion Matrix:\n",
      "[[12.   0. ]\n",
      " [ 8.4  0.2]]\n",
      "\n",
      "K = 10, Accuracy: 0.5700 +/- 0.1250\n",
      "Confusion Matrix:\n",
      "[[5.9 0.1]\n",
      " [4.3 0. ]]\n",
      "\n",
      "Model: ['usability_positive', 'design features_negative', 'general_neutral', 'price_positive', 'quality_positive', 'operation performance_negative', 'operation performance_positive', 'general_negative', 'design features_positive']\n",
      "K = 5, Accuracy: 0.5910 +/- 0.0953\n",
      "Confusion Matrix:\n",
      "[[12.   0. ]\n",
      " [ 8.4  0.2]]\n",
      "\n",
      "K = 10, Accuracy: 0.5700 +/- 0.1250\n",
      "Confusion Matrix:\n",
      "[[5.9 0.1]\n",
      " [4.3 0. ]]\n",
      "\n",
      "Model: ['usability_positive', 'design features_negative', 'general_neutral', 'price_positive', 'quality_positive', 'operation performance_negative', 'operation performance_positive', 'general_negative', 'design features_positive', 'general_positive']\n",
      "K = 5, Accuracy: 0.5814 +/- 0.0894\n",
      "Confusion Matrix:\n",
      "[[12.   0. ]\n",
      " [ 8.6  0. ]]\n",
      "\n",
      "K = 10, Accuracy: 0.5700 +/- 0.1250\n",
      "Confusion Matrix:\n",
      "[[5.9 0.1]\n",
      " [4.3 0. ]]\n",
      "\n",
      "Model: ['usability_positive', 'design features_negative', 'general_neutral', 'price_positive', 'quality_positive', 'operation performance_negative', 'operation performance_positive', 'general_negative', 'design features_positive', 'general_positive', 'quality_negative']\n",
      "K = 5, Accuracy: 0.5814 +/- 0.0894\n",
      "Confusion Matrix:\n",
      "[[12.   0. ]\n",
      " [ 8.6  0. ]]\n",
      "\n",
      "K = 10, Accuracy: 0.5700 +/- 0.1250\n",
      "Confusion Matrix:\n",
      "[[5.9 0.1]\n",
      " [4.3 0. ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data\n",
    "df = absa_movement_no_known_df()\n",
    "\n",
    "# Select relevant features\n",
    "features = ['usability_positive', 'design features_negative', 'general_neutral', 'price_positive', \n",
    "            'quality_positive', 'operation performance_negative', 'operation performance_positive', \n",
    "            'general_negative', 'design features_positive', 'general_positive', 'quality_negative']\n",
    "\n",
    "# Define a range of K values\n",
    "k_values = (5,10)\n",
    "\n",
    "# Define a list of models to train\n",
    "models = []\n",
    "for i in range(len(features)):\n",
    "    models.append(features[:i+1])\n",
    "\n",
    "# Define a dictionary to store the accuracy values for each model and K value\n",
    "accuracy_dict = {str(model): {k: [] for k in k_values} for model in models}\n",
    "\n",
    "# Define a dictionary to store the confusion matrix for each model and K value\n",
    "confusion_dict = {str(model): {k: [] for k in k_values} for model in models}\n",
    "\n",
    "# Loop through the models and K values and perform K-fold cross-validation\n",
    "for model in models:\n",
    "    X = df[model].values\n",
    "    y = df['to_predict'].values\n",
    "    for k in k_values:\n",
    "        kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            \n",
    "            # Define and fit the logistic regression model\n",
    "            clf = LogisticRegression()\n",
    "            clf.fit(X_train, y_train)\n",
    "            \n",
    "            # Predict on the test data and calculate the accuracy and confusion matrix\n",
    "            y_pred = clf.predict(X_test)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            confusion = confusion_matrix(y_test, y_pred)\n",
    "            \n",
    "            # Store the accuracy and confusion matrix in the dictionaries\n",
    "            accuracy_dict[str(model)][k].append(accuracy)\n",
    "            confusion_dict[str(model)][k].append(confusion)\n",
    "\n",
    "# Visualize accuracy vs number of features\n",
    "num_features = list(range(1, len(features)+1))\n",
    "accuracy_k5 = [np.mean(accuracy_dict[str(model)][5]) for model in models]\n",
    "accuracy_k10 = [np.mean(accuracy_dict[str(model)][10]) for model in models]\n",
    "\n",
    "plt.plot(num_features, accuracy_k5, label='K = 5')\n",
    "plt.plot(num_features, accuracy_k10, label='K = 10')\n",
    "plt.xlabel('Number of Predictor Variables')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs Number of Features')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Print the results\n",
    "for model in models:\n",
    "    print(f'Model: {model}')\n",
    "    for k in k_values:\n",
    "        accuracy_values = accuracy_dict[str(model)][k]\n",
    "        mean_accuracy = np.mean(accuracy_values)\n",
    "        std_accuracy = np.std(accuracy_values)\n",
    "        mean_confusion = np.mean(confusion_dict[str(model)][k], axis=0)\n",
    "        print(f'K = {k}, Accuracy: {mean_accuracy:.4f} +/- {std_accuracy:.4f}')\n",
    "        print('Confusion Matrix:')\n",
    "        print(mean_confusion)\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "679636c5-b220-4121-9607-935cfaf0d5e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.20.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "280e4348acd849319406726aa09dd92a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(ToggleButtons(description='K Value:', options=(5, 10), value=5), IntSlider(value=1, desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "import plotly.offline as pyo\n",
    "pyo.init_notebook_mode(connected=True)\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Your existing data loading and model training code\n",
    "\n",
    "# Function to visualize the confusion matrix\n",
    "def plot_confusion_matrix(confusion_matrix, title):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(confusion_matrix, annot=True, fmt='g', cmap='viridis')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Interactive widget to select K value\n",
    "k_slider = widgets.ToggleButtons(options=[5, 10], description='K Value:')\n",
    "\n",
    "# Interactive widget to select the number of features\n",
    "num_features_slider = widgets.IntSlider(min=1, max=len(features), description='Features:')\n",
    "\n",
    "# Function to update the confusion matrix plot\n",
    "def update_plot(k, num_features):\n",
    "    selected_model = num_features - 1\n",
    "    mean_confusion = np.mean(confusion_dict[str(models[selected_model])][k], axis=0)\n",
    "    plot_confusion_matrix(mean_confusion, f'Num Features: {len(models[selected_model])}, K = {k}')\n",
    "\n",
    "# Interactive widget to display the confusion matrix based on the selected K value and number of features\n",
    "interactive_plot = widgets.interactive(update_plot, k=k_slider, num_features=num_features_slider)\n",
    "\n",
    "# Display the interactive widgets\n",
    "display(interactive_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921c6ecf",
   "metadata": {},
   "source": [
    "## Multi-Layer Perceptron with different number of hidden units (1 layer) (no previous close price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fd2acbd-322b-47c7-b472-2cbd8ef12edb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a362df08932b414ead66792900e3dfa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='Hidden Units:', max=20, min=1), Output()), _dom_classes=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Load data\n",
    "df = absa_movement_no_known_df()\n",
    "\n",
    "# Select relevant features\n",
    "features = ['usability_positive', 'design features_negative', 'general_neutral', 'price_positive', \n",
    "            'quality_positive', 'operation performance_negative', 'operation performance_positive', \n",
    "            'general_negative', 'design features_positive', 'general_positive', 'quality_negative']\n",
    "\n",
    "# Use all features for the MLP model\n",
    "X = df[features].values\n",
    "y = df['to_predict'].values\n",
    "\n",
    "# Set the range of hidden units to test\n",
    "hidden_units = list(range(1, 21))\n",
    "\n",
    "# Define a dictionary to store the accuracy values and loss curves for each number of hidden units\n",
    "accuracy_dict = {hidden_unit: [] for hidden_unit in hidden_units}\n",
    "loss_curves_dict = {hidden_unit: [] for hidden_unit in hidden_units}\n",
    "\n",
    "# Train MLP models with different numbers of hidden units\n",
    "for hidden_unit in hidden_units:\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # Define and fit the MLP model\n",
    "        clf = MLPClassifier(hidden_layer_sizes=(hidden_unit,), random_state=42, max_iter=2000, tol=1e-5)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        # Predict on the test data and calculate the accuracy\n",
    "        y_pred = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        # Store the accuracy and loss curve in the dictionaries\n",
    "        accuracy_dict[hidden_unit].append(accuracy)\n",
    "        loss_curves_dict[hidden_unit].append(clf.loss_curve_)\n",
    "\n",
    "# Function to plot training progress and accuracy\n",
    "def plot_results(hidden_unit):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Plot training progress (loss curve) on the left subplot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for i, loss_curve in enumerate(loss_curves_dict[hidden_unit]):\n",
    "        plt.plot(loss_curve, label=f'Fold {i+1}')\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'Training Progress (Loss) - {hidden_unit} Hidden Units')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot accuracy on the right subplot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    accuracies = [np.mean(accuracy_dict[h]) for h in hidden_units]\n",
    "    plt.bar(hidden_units, accuracies)\n",
    "    plt.xlabel('Number of Hidden Units')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy vs Number of Hidden Units')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Interactive widget to select the number of hidden units\n",
    "hidden_units_slider = widgets.IntSlider(min=1, max=20, description='Hidden Units:')\n",
    "\n",
    "# Function to update the plot based on the selected number of hidden units\n",
    "def update_plot(hidden_unit):\n",
    "    plot_results(hidden_unit)\n",
    "\n",
    "# the training progress and accuracy based on the selected number of hidden units\n",
    "interactive_plot = widgets.interactive(update_plot, hidden_unit=hidden_units_slider)\n",
    "\n",
    "# Display the interactive widgets\n",
    "display(interactive_plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e19f677a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91bc1b5d14924c43860aab3f71adeea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training models:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ace9465942874f0993d477d48725811c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='Hidden Units:', max=20, min=1), Output()), _dom_classes=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "# Your data loading and feature selection code\n",
    "# Load data\n",
    "df = absa_movement_df()\n",
    "\n",
    "# Select relevant features\n",
    "features = ['usability_positive', 'design features_negative', 'general_neutral', 'price_positive', \n",
    "            'quality_positive', 'operation performance_negative', 'operation performance_positive', \n",
    "            'general_negative', 'design features_positive', 'general_positive', 'quality_negative']\n",
    "\n",
    "# Use all features for the MLP model\n",
    "X = df[features].values\n",
    "y = df['to_predict'].values\n",
    "\n",
    "# Set the range of hidden units to test\n",
    "hidden_units = list(range(1, 21))\n",
    "\n",
    "# Define a dictionary to store the accuracy values and loss curves for each number of hidden units\n",
    "accuracy_dict = {hidden_unit: [] for hidden_unit in hidden_units}\n",
    "loss_curves_dict = {hidden_unit: [] for hidden_unit in hidden_units}\n",
    "\n",
    "# Train MLP models with different numbers of hidden units\n",
    "for hidden_unit in tqdm(hidden_units, desc=\"Training models\"):\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # Define and fit the MLP model\n",
    "        clf = MLPClassifier(hidden_layer_sizes=(hidden_unit,), random_state=42, max_iter=20000, tol=1e-5)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        # Predict on the test data and calculate the accuracy\n",
    "        y_pred = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        # Store the accuracy and loss curve in the dictionaries\n",
    "        accuracy_dict[hidden_unit].append(accuracy)\n",
    "        loss_curves_dict[hidden_unit].append(clf.loss_curve_)\n",
    "\n",
    "# Function to plot training progress and accuracy\n",
    "def plot_results(hidden_unit):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Plot training progress (loss curve) on the left subplot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for i, loss_curve in enumerate(loss_curves_dict[hidden_unit]):\n",
    "        plt.plot(loss_curve, label=f'Fold {i+1}')\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'Training Progress (Loss) - {hidden_unit} Hidden Units')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot accuracy on the right subplot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    accuracies = [np.mean(accuracy_dict[h]) for h in hidden_units]\n",
    "    selected_accuracy = np.mean(accuracy_dict[hidden_unit])\n",
    "    plt.bar(hidden_units, accuracies)\n",
    "    plt.bar(hidden_unit, selected_accuracy, color='orange', label=f'Selected: {hidden_unit}')\n",
    "    plt.xlabel('Number of Hidden Units')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title(f'Accuracy vs Number of Hidden Units (Selected: {hidden_unit}, Acc: {selected_accuracy:.4f})')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Interactive widget to select the number of hidden units\n",
    "hidden_units_slider = widgets.IntSlider(min=1, max=20, description='Hidden Units:')\n",
    "\n",
    "# Function to update the plot based on the selected number of hidden units\n",
    "def update_plot(hidden_unit):\n",
    "    plot_results(hidden_unit)\n",
    "\n",
    "# Interactive widget to display the training progress and accuracy based on the selected number of hidden units\n",
    "interactive_plot = widgets.interactive(update_plot, hidden_unit=hidden_units_slider)\n",
    "\n",
    "# Display the interactive widgets\n",
    "display(interactive_plot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772e3ee6",
   "metadata": {},
   "source": [
    "Above result: best hiddensize is **8**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babb18ed",
   "metadata": {},
   "source": [
    "### Prediction on the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fae378c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0597eb9695a4b709c00df7c39d1badd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>usability_positive</th>\n",
       "      <th>design features_negative</th>\n",
       "      <th>general_neutral</th>\n",
       "      <th>price_positive</th>\n",
       "      <th>quality_positive</th>\n",
       "      <th>operation performance_negative</th>\n",
       "      <th>operation performance_positive</th>\n",
       "      <th>general_negative</th>\n",
       "      <th>design features_positive</th>\n",
       "      <th>general_positive</th>\n",
       "      <th>quality_negative</th>\n",
       "      <th>known</th>\n",
       "      <th>to_predict</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.37</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.184211</td>\n",
       "      <td>0.763158</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     usability_positive  design features_negative  general_neutral   \n",
       "0              0.058824                  0.029412         0.000000  \\\n",
       "1              0.055556                  0.083333         0.000000   \n",
       "2              0.035714                  0.000000         0.000000   \n",
       "3              0.038462                  0.000000         0.038462   \n",
       "4              0.052632                  0.078947         0.000000   \n",
       "..                  ...                       ...              ...   \n",
       "98             0.045455                  0.000000         0.000000   \n",
       "99             0.055556                  0.000000         0.000000   \n",
       "100            0.037037                  0.037037         0.000000   \n",
       "101            0.034483                  0.137931         0.000000   \n",
       "102            0.125000                  0.000000         0.000000   \n",
       "\n",
       "     price_positive  quality_positive  operation performance_negative   \n",
       "0          0.088235          0.147059                        0.058824  \\\n",
       "1          0.055556          0.250000                        0.111111   \n",
       "2          0.107143          0.285714                        0.035714   \n",
       "3          0.115385          0.307692                        0.076923   \n",
       "4          0.105263          0.210526                        0.078947   \n",
       "..              ...               ...                             ...   \n",
       "98         0.227273          0.318182                        0.181818   \n",
       "99         0.277778          0.277778                        0.000000   \n",
       "100        0.074074          0.222222                        0.074074   \n",
       "101        0.068966          0.379310                        0.034483   \n",
       "102        0.125000          0.562500                        0.000000   \n",
       "\n",
       "     operation performance_positive  general_negative   \n",
       "0                          0.205882          0.176471  \\\n",
       "1                          0.138889          0.166667   \n",
       "2                          0.178571          0.178571   \n",
       "3                          0.230769          0.038462   \n",
       "4                          0.105263          0.105263   \n",
       "..                              ...               ...   \n",
       "98                         0.181818          0.090909   \n",
       "99                         0.222222          0.055556   \n",
       "100                        0.185185          0.111111   \n",
       "101                        0.275862          0.103448   \n",
       "102                        0.187500          0.187500   \n",
       "\n",
       "     design features_positive  general_positive  quality_negative  known   \n",
       "0                    0.264706          0.676471          0.117647   0.37  \\\n",
       "1                    0.166667          0.666667          0.111111  -0.19   \n",
       "2                    0.178571          0.714286          0.035714  -0.04   \n",
       "3                    0.269231          0.653846          0.000000   0.01   \n",
       "4                    0.184211          0.763158          0.078947  -0.14   \n",
       "..                        ...               ...               ...    ...   \n",
       "98                   0.136364          0.590909          0.136364  -0.17   \n",
       "99                   0.055556          0.833333          0.000000  -0.04   \n",
       "100                  0.148148          0.592593          0.037037   0.12   \n",
       "101                  0.137931          0.724138          0.068966   0.01   \n",
       "102                  0.187500          0.750000          0.062500  -0.12   \n",
       "\n",
       "     to_predict  predictions  \n",
       "0            -1           -1  \n",
       "1            -1           -1  \n",
       "2             1            1  \n",
       "3            -1           -1  \n",
       "4            -1           -1  \n",
       "..          ...          ...  \n",
       "98           -1            1  \n",
       "99            1            1  \n",
       "100           1           -1  \n",
       "101          -1           -1  \n",
       "102           1           -1  \n",
       "\n",
       "[103 rows x 14 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Your data loading and feature selection code\n",
    "# Load data\n",
    "df = absa_movement_df()\n",
    "\n",
    "# Select relevant features\n",
    "features = ['usability_positive', 'design features_negative', 'general_neutral', 'price_positive', \n",
    "            'quality_positive', 'operation performance_negative', 'operation performance_positive', \n",
    "            'general_negative', 'design features_positive', 'general_positive', 'quality_negative']\n",
    "\n",
    "# Use all features for the MLP model\n",
    "X = df[features].values\n",
    "y = df['to_predict'].values\n",
    "\n",
    "# Define the number of hidden units that give the best result\n",
    "best_hidden_units = 8\n",
    "\n",
    "# Initialize KFold with the desired number of splits\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize an empty array to store the predictions\n",
    "y_pred_all = np.empty_like(y)\n",
    "\n",
    "# Train the MLP model using cross-validation and display progress with tqdm\n",
    "for train_index, test_index in tqdm(kf.split(X), desc=\"Predicting\", total=kf.get_n_splits()):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Define and fit the MLP model\n",
    "    clf = MLPClassifier(hidden_layer_sizes=(best_hidden_units,), random_state=42, max_iter=20000, tol=1e-5)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test data\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Store the predictions in the corresponding indices of y_pred_all\n",
    "    y_pred_all[test_index] = y_pred\n",
    "\n",
    "# Create a new column in the original DataFrame to store the predictions\n",
    "df['predictions'] = y_pred_all\n",
    "\n",
    "# Select only the specified columns, along with 'to_predict' and 'predictions' columns\n",
    "result_df = df[features + ['known', 'to_predict', 'predictions']]\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5725de2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('./data/6505_MLP_predicted_movement.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fece76ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>usability_positive</th>\n",
       "      <th>design features_negative</th>\n",
       "      <th>general_neutral</th>\n",
       "      <th>price_positive</th>\n",
       "      <th>quality_positive</th>\n",
       "      <th>operation performance_negative</th>\n",
       "      <th>operation performance_positive</th>\n",
       "      <th>general_negative</th>\n",
       "      <th>design features_positive</th>\n",
       "      <th>general_positive</th>\n",
       "      <th>quality_negative</th>\n",
       "      <th>to_predict</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.184211</td>\n",
       "      <td>0.763158</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     usability_positive  design features_negative  general_neutral   \n",
       "0              0.058824                  0.029412         0.000000  \\\n",
       "1              0.055556                  0.083333         0.000000   \n",
       "2              0.035714                  0.000000         0.000000   \n",
       "3              0.038462                  0.000000         0.038462   \n",
       "4              0.052632                  0.078947         0.000000   \n",
       "..                  ...                       ...              ...   \n",
       "93             0.000000                  0.052632         0.000000   \n",
       "94             0.000000                  0.000000         0.157895   \n",
       "97             0.083333                  0.000000         0.000000   \n",
       "99             0.055556                  0.000000         0.000000   \n",
       "101            0.034483                  0.137931         0.000000   \n",
       "\n",
       "     price_positive  quality_positive  operation performance_negative   \n",
       "0          0.088235          0.147059                        0.058824  \\\n",
       "1          0.055556          0.250000                        0.111111   \n",
       "2          0.107143          0.285714                        0.035714   \n",
       "3          0.115385          0.307692                        0.076923   \n",
       "4          0.105263          0.210526                        0.078947   \n",
       "..              ...               ...                             ...   \n",
       "93         0.000000          0.052632                        0.263158   \n",
       "94         0.000000          0.210526                        0.052632   \n",
       "97         0.000000          0.208333                        0.083333   \n",
       "99         0.277778          0.277778                        0.000000   \n",
       "101        0.068966          0.379310                        0.034483   \n",
       "\n",
       "     operation performance_positive  general_negative   \n",
       "0                          0.205882          0.176471  \\\n",
       "1                          0.138889          0.166667   \n",
       "2                          0.178571          0.178571   \n",
       "3                          0.230769          0.038462   \n",
       "4                          0.105263          0.105263   \n",
       "..                              ...               ...   \n",
       "93                         0.105263          0.263158   \n",
       "94                         0.210526          0.157895   \n",
       "97                         0.250000          0.166667   \n",
       "99                         0.222222          0.055556   \n",
       "101                        0.275862          0.103448   \n",
       "\n",
       "     design features_positive  general_positive  quality_negative  to_predict   \n",
       "0                    0.264706          0.676471          0.117647          -1  \\\n",
       "1                    0.166667          0.666667          0.111111          -1   \n",
       "2                    0.178571          0.714286          0.035714           1   \n",
       "3                    0.269231          0.653846          0.000000          -1   \n",
       "4                    0.184211          0.763158          0.078947          -1   \n",
       "..                        ...               ...               ...         ...   \n",
       "93                   0.157895          0.368421          0.105263          -1   \n",
       "94                   0.052632          0.473684          0.000000          -1   \n",
       "97                   0.125000          0.583333          0.041667          -1   \n",
       "99                   0.055556          0.833333          0.000000           1   \n",
       "101                  0.137931          0.724138          0.068966          -1   \n",
       "\n",
       "     predictions  \n",
       "0             -1  \n",
       "1             -1  \n",
       "2              1  \n",
       "3             -1  \n",
       "4             -1  \n",
       "..           ...  \n",
       "93            -1  \n",
       "94            -1  \n",
       "97            -1  \n",
       "99             1  \n",
       "101           -1  \n",
       "\n",
       "[67 rows x 13 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.loc[result_df['to_predict']==result_df['predictions']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7deb03",
   "metadata": {},
   "source": [
    "## MLP with stock price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e4d0e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/donglingu/opt/anaconda3/lib/python3.8/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c655bef314244c9acfe4193703cda23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training models:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9791e1ee14274958a2f07f641f792a5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='Hidden Units:', max=20, min=1), Output()), _dom_classes=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "# Your data loading and feature selection code\n",
    "# Load data\n",
    "df = absa_movement_df()\n",
    "\n",
    "# Select relevant features\n",
    "features = ['known','usability_positive', 'design features_negative', 'general_neutral', 'price_positive', \n",
    "            'quality_positive', 'operation performance_negative', 'operation performance_positive', \n",
    "            'general_negative', 'design features_positive', 'general_positive', 'quality_negative']\n",
    "\n",
    "# Use all features for the MLP model\n",
    "X = df[features].values\n",
    "y = df['to_predict'].values\n",
    "\n",
    "# Set the range of hidden units to test\n",
    "hidden_units = list(range(1, 21))\n",
    "\n",
    "# Define a dictionary to store the accuracy values and loss curves for each number of hidden units\n",
    "accuracy_dict = {hidden_unit: [] for hidden_unit in hidden_units}\n",
    "loss_curves_dict = {hidden_unit: [] for hidden_unit in hidden_units}\n",
    "\n",
    "# Train MLP models with different numbers of hidden units\n",
    "for hidden_unit in tqdm(hidden_units, desc=\"Training models\"):\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # Define and fit the MLP model\n",
    "        clf = MLPClassifier(hidden_layer_sizes=(hidden_unit,), random_state=42, max_iter=20000, tol=1e-5)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        # Predict on the test data and calculate the accuracy\n",
    "        y_pred = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        # Store the accuracy and loss curve in the dictionaries\n",
    "        accuracy_dict[hidden_unit].append(accuracy)\n",
    "        loss_curves_dict[hidden_unit].append(clf.loss_curve_)\n",
    "\n",
    "# Function to plot training progress and accuracy\n",
    "def plot_results(hidden_unit):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Plot training progress (loss curve) on the left subplot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for i, loss_curve in enumerate(loss_curves_dict[hidden_unit]):\n",
    "        plt.plot(loss_curve, label=f'Fold {i+1}')\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'Training Progress (Loss) - {hidden_unit} Hidden Units')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot accuracy on the right subplot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    accuracies = [np.mean(accuracy_dict[h]) for h in hidden_units]\n",
    "    selected_accuracy = np.mean(accuracy_dict[hidden_unit])\n",
    "    plt.bar(hidden_units, accuracies)\n",
    "    plt.bar(hidden_unit, selected_accuracy, color='orange', label=f'Selected: {hidden_unit}')\n",
    "    plt.xlabel('Number of Hidden Units')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title(f'Accuracy vs Number of Hidden Units (Selected: {hidden_unit}, Acc: {selected_accuracy:.4f})')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Interactive widget to select the number of hidden units\n",
    "hidden_units_slider = widgets.IntSlider(min=1, max=20, description='Hidden Units:')\n",
    "\n",
    "# Function to update the plot based on the selected number of hidden units\n",
    "def update_plot(hidden_unit):\n",
    "    plot_results(hidden_unit)\n",
    "\n",
    "# Interactive widget to display the training progress and accuracy based on the selected number of hidden units\n",
    "interactive_plot = widgets.interactive(update_plot, hidden_unit=hidden_units_slider)\n",
    "\n",
    "# Display the interactive widgets\n",
    "display(interactive_plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ec8af1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b49d095",
   "metadata": {},
   "source": [
    "# RNN (History) + MLP (Day Prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14d3f8b",
   "metadata": {},
   "source": [
    "## 1. GRU (History) with Instruction-Modulated Reset Hidden State"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e74a956",
   "metadata": {},
   "source": [
    "Instruction-Modulated Reset Gate: This approach modifies the reset gate to incorporate the instruction vector. By conditioning the reset gate on the instruction, the model can adjust its short-term dependency learning based on the provided instruction.\n",
    "\n",
    "Advantages: It allows the model to specifically control the influence of past information on the current hidden state based on the instruction. This can be useful when the instruction vector carries information that should **primarily affect short-term dependencies**.\n",
    "Suggested Use: Choose this approach when the instruction vector should mainly influence the model's ability to reset the hidden state or capture short-term dependencies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851b62c5",
   "metadata": {},
   "source": [
    "class CustomGRUCellWithInstruction(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, instruction_size):\n",
    "        ...\n",
    "        self.reset_gate = nn.Sequential(\n",
    "            nn.Linear(input_size + hidden_size + instruction_size, hidden_size),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        ...\n",
    "\n",
    "    def forward(self, x, h_prev, instruction):\n",
    "        combined = torch.cat((x, h_prev), dim=1)\n",
    "        combined_with_instruction = torch.cat((combined, instruction), dim=1)\n",
    "        reset = self.reset_gate(combined_with_instruction)\n",
    "        ...\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
